# Tiny MoA (Mixture of Agents) PoC ìƒì„¸ ëª…ì„¸ì„œ

> **ì‘ì„±ì¼:** 2026ë…„ 1ì›” 23ì¼  
> **í”„ë¡œì íŠ¸ëª…:** Tiny MoA (Mixture of Agents) Proof of Concept  
> **ëª©í‘œ:** 4B ëª¨ë¸ í•˜ë‚˜ë¥¼ ë„ìš°ëŠ” ê²ƒë³´ë‹¤ íš¨ìœ¨ì ìœ¼ë¡œ, 1.2B "Brain" ëª¨ë¸ê³¼ 90M~600Mê¸‰ "Specialist" ëª¨ë¸ë“¤ì„ ì¡°í•©í•˜ì—¬ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ëŠ” ì•„í‚¤í…ì²˜ ì„¤ê³„ ë° êµ¬í˜„

---

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### 1.1 í•µì‹¬ ì•„ì´ë””ì–´

"GPU Poor"ë¥¼ ìœ„í•œ **Tiny MoA (Mixture of Agents)** ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤.

- **ì¤‘ì•™ ì‚¬ë ¹ê´€ (Brain):** ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ê³ , ì–´ë–¤ ì „ë¬¸ê°€ ëª¨ë¸ì„ í˜¸ì¶œí• ì§€ ê²°ì •
- **ì „ë¬¸ê°€ ê·¸ë£¹ (Specialists):** ê° ë¶„ì•¼(ì½”ë”©, ì¶”ë¡ , ë„êµ¬í˜¸ì¶œ, OCR ë“±)ì— íŠ¹í™”ëœ ì´ˆì†Œí˜• ëª¨ë¸ë“¤

ì´ êµ¬ì¡°ëŠ” 2026ë…„ 1ì›” í˜„ì¬ ìµœì‹  "ì‘ì§€ë§Œ ê°•ë ¥í•œ(Small but Powerful)" ëª¨ë¸ íŠ¸ë Œë“œë¥¼ í™œìš©í•©ë‹ˆë‹¤:
- **LiquidAI LFM2.5 ì‹œë¦¬ì¦ˆ:** 28T í† í°ìœ¼ë¡œ í•™ìŠµëœ 1.2Bê¸‰ ê³ ì„±ëŠ¥ ëª¨ë¸
- **TII Falcon-H1-Tiny ì‹œë¦¬ì¦ˆ:** 90M~600Mê¸‰ Hybrid (Mamba+Attention) ì•„í‚¤í…ì²˜

### 1.2 ì™œ ì´ ì ‘ê·¼ë²•ì¸ê°€?

| ì „í†µì  ì ‘ê·¼ | Tiny MoA ì ‘ê·¼ |
|------------|---------------|
| 4B~7B ë‹¨ì¼ ëª¨ë¸ | 1.2B Brain + 90M~600M Specialists |
| VRAM: 8~16GB í•„ìš” | VRAM: 2~4GBë¡œ ì¶©ë¶„ |
| ë‹¨ì¼ ëª¨ë¸ì˜ í•œê³„ | ë¶„ì•¼ë³„ ìµœì í™”ëœ ì „ë¬¸ê°€ |
| ë¡œë”© ì‹œê°„ ê¹€ | ê²½ëŸ‰ ëª¨ë¸ë¡œ ì¦‰ì‹œ ì‘ë‹µ |

---

## 2. ëª¨ë¸ ë¶„ì„ ë° ì„ ì •

### 2.1 Brain ëª¨ë¸ í›„ë³´

#### LiquidAI LFM2.5-1.2B-Thinking (ê¶Œì¥)
| í•­ëª© | ì‚¬ì–‘ |
|------|------|
| **íŒŒë¼ë¯¸í„°** | 1.17B |
| **ì•„í‚¤í…ì²˜** | 16 layers (10 LIV convolution + 6 GQA blocks) |
| **í•™ìŠµ í† í°** | 28T tokens |
| **ì»¨í…ìŠ¤íŠ¸** | 32,768 tokens |
| **ì§€ì› ì–¸ì–´** | English, Arabic, Chinese, French, German, Japanese, Korean, Spanish |
| **ì¶”ì²œ ìš©ë„** | Agentic tasks, Data extraction, RAG |
| **ë¹„ì¶” ìš©ë„** | Knowledge-intensive tasks, Programming (â†’ Specialistì—ê²Œ ìœ„ì„) |

**ì„ ì • ì´ìœ :**
- 1Bê¸‰ì—ì„œ GPQA(38.89), IFEval(86.23), BFCLv3(49.12) ì••ë„ì  ì„±ëŠ¥
- í•œêµ­ì–´ í¬í•¨ 8ê°œ ì–¸ì–´ ì§€ì›
- GGUF, ONNX, MLX ëª¨ë“  í¬ë§· ì œê³µ
- CPUì—ì„œ 116 tok/s (AMD Ryzen) ë‹¬ì„±

#### LiquidAI LFM2.5-1.2B-Instruct (ëŒ€ì•ˆ)
- Thinking ëª¨ë¸ê³¼ ë™ì¼ ì•„í‚¤í…ì²˜
- ë” ì§§ì€ ì‘ë‹µ ìƒì„± (ë‚®ì€ latency)
- ì¼ë°˜ ì§€ì‹œ ë”°ë¥´ê¸°ì— ìµœì í™”

### 2.2 Specialist ëª¨ë¸ ë¶„ì„

#### 2.2.1 ë„êµ¬ í˜¸ì¶œ (Tool Calling)

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | íŠ¹ì§• | BFCL Score |
|------|----------|------|------------|
| **Falcon-H1-Tiny-Tool-Calling** | 90M | Hybrid Mamba+Attention, ê´€ë ¨ì„± íŒë‹¨ 94.44% | 41.23% |
| Google FunctionGemma | 270M | Gemma3 ê¸°ë°˜, íŒŒì¸íŠœë‹ í•„ìš” | - |

**Falcon-H1-Tiny-Tool-Calling ì„ ì • ì´ìœ :**
- 90Mì„ì—ë„ ê´€ë ¨ì„± íŒë‹¨ ì •í™•ë„ **94.44%** (FunctionGemma 61.10% ì••ë„)
- JSON í•¨ìˆ˜ í˜¸ì¶œ í¬ë§· ì •í™•íˆ ìƒì„±
- ë¸”ë¡œê·¸ì— ë”°ë¥´ë©´ CoT(Chain-of-Thought) ë°°ì œë¡œ ë°˜ë³µ ë¬¸ì œ í•´ê²°

#### 2.2.2 ì¶”ë¡ /ìˆ˜í•™ (Reasoning)

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | AIME24 pass@1 | MATH500 | íŠ¹ì§• |
|------|----------|---------------|---------|------|
| **Falcon-H1-Tiny-R-0.6B** | 600M | 75.0% | 94.0% | GRPO ì ìš©, SoTA |
| Falcon-H1-Tiny-R-90M | 90M | 5.0% | 39.7% | ê²½ëŸ‰ ë²„ì „ |

**Falcon-H1-Tiny-R-0.6B ì„ ì • ì´ìœ :**
- AIME24ì—ì„œ MobileLLM-R1-950M(15.5%)ì„ 5ë°° ì••ë„
- Anti-curriculum í•™ìŠµ: ì¶”ë¡  ë°ì´í„°ë¡œ ì²˜ìŒë¶€í„° ì‚¬ì „í•™ìŠµ
- GRPO(Group Relative Policy Optimization) ê°•í™”í•™ìŠµ ì ìš©
- **ì½”ë”©ë„ ê°€ëŠ¥:** LiveCodeBench v6ì—ì„œ 39.0% ë‹¬ì„± (MobileLLM-R1 19.9% ì••ë„)

> **ğŸ’¡ Coder(90M) vs Reasoner(0.6B) ì„ íƒ ê¸°ì¤€:**
> | ìš”ì²­ ìœ í˜• | ì¶”ì²œ ëª¨ë¸ | ì´ìœ  |
> |-----------|-----------|------|
> | í•¨ìˆ˜ ì™„ì„±, ê°„ë‹¨í•œ ì½”ë“œ | Coder (90M) | FIM ì§€ì›, ë¹ ë¦„ |
> | ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œ, ë…¼ë¦¬ì  êµ¬í˜„ | **Reasoner (0.6B)** | ì¶”ë¡ ë ¥ í•„ìš” |
> | AIME/ê²½ì‹œëŒ€íšŒ ìŠ¤íƒ€ì¼ ì½”ë”© | **Reasoner (0.6B)** | ìˆ˜í•™+ì½”ë“œ ë³µí•© |

#### 2.2.3 ì½”ë”© (Coding)

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | HumanEval+ | MBPP+ | FIM ì§€ì› |
|------|----------|------------|-------|----------|
| **Falcon-H1-Tiny-Coder** | 90M | 14.63% | 34.92% | âœ… |
| Qwen2.5-Coder-0.5B | 500M | 23.17% | 48.67% | âœ… |

**Falcon-H1-Tiny-Coder ì„ ì • ì´ìœ :**
- Python FIM(Fill-in-the-Middle) ì§€ì›
- 90Më¡œ Qwen 0.5B ëŒ€ë¹„ 5ë°° ì‘ì§€ë§Œ ê¸°ë³¸ ì½”ë”© ê°€ëŠ¥
- Continue VS Code í”ŒëŸ¬ê·¸ì¸ê³¼ ì—°ë™ ê²€ì¦ë¨

#### 2.2.4 ë‹¤êµ­ì–´ (Multilingual)

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | IFEVAL | M-MMLU | ì§€ì› ì–¸ì–´ |
|------|----------|--------|--------|-----------|
| **Falcon-H1-Tiny-Multilingual** | 100M | 52.00% | 45.00% | 17ê°œ ì–¸ì–´ |
| SmolLM2-135M-Instruct | 135M | 30.69% | 25.63% | - |

**Falcon-H1-Tiny-Multilingual ì„ ì • ì´ìœ :**
- 17ê°œ ì–¸ì–´ ì§€ì› (í•œêµ­ì–´ í¬í•¨)
- IFEVAL 52% (SmolLM2 ëŒ€ë¹„ 21%p ìš°ìœ„)
- 100Mìœ¼ë¡œ ê·¹ë„ë¡œ ê°€ë²¼ì›€

#### 2.2.5 OCR/ë¬¸ì„œ ì²˜ë¦¬

| ëª¨ë¸/ë„êµ¬ | íŒŒë¼ë¯¸í„° | íŠ¹ì§• | ì†ë„ |
|-----------|----------|------|------|
| **docling** (ë¼ì´ë¸ŒëŸ¬ë¦¬) | - | PDF, DOCX, PPTX, ì´ë¯¸ì§€ ë“± ë‹¤ì–‘í•œ í¬ë§· | - |
| **LightOnOCR-2-1B** | 1B | End-to-End VLM, ìˆ˜ì‹/í‘œ ì§€ì› | 5.71 pages/s (H100) |
| GraniteDocling | 258M | IBM, Docling í†µí•© | - |

**ê¶Œì¥ ì¡°í•©:**
1. ê¸°ë³¸: `docling` ë¼ì´ë¸ŒëŸ¬ë¦¬ (ëª¨ë¸ ì—†ì´ ë¬¸ì„œ íŒŒì‹±)
2. ê³ ê¸‰: `LightOnOCR-2-1B` (ìŠ¤ìº” ë¬¸ì„œ, ìˆ˜ì‹ ì¸ì‹ í•„ìš”ì‹œ)

#### 2.2.6 ì˜¤ë””ì˜¤ (Audio) - ì„ íƒì 

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | íŠ¹ì§• |
|------|----------|------|
| **LFM2.5-Audio-1.5B** | 1.5B | ìŒì„±â†”í…ìŠ¤íŠ¸ Native, 8x ë¹ ë¥¸ ë””í† í¬ë‚˜ì´ì € |

**ì„ ì • ì´ìœ :**
- íŒŒì´í”„ë¼ì¸ ë°©ì‹(ASRâ†’LLMâ†’TTS) ëŒ€ë¹„ End-to-Endë¡œ ì§€ì—° ìµœì†Œí™”
- Multi-turn, Multi-modal ì±„íŒ… ì§€ì›

#### 2.2.7 í•œêµ­ì–´ íŠ¹í™”

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | ìš©ë„ |
|------|----------|------|
| **HybriKo-117M-LinuxFC-SFT-v2** | 117M | í•œêµ­ì–´ Linux ëª…ë ¹ì–´ ìƒì„± |
| LFM2.5-1.2B-JP | 1.2B | ì¼ë³¸ì–´ íŠ¹í™” (ì°¸ê³ ìš©) |

**HybriKo í™œìš© ì´ìœ :**
- ê¸°ì›…ë‹˜ì˜ ì»¤ìŠ¤í…€ ëª¨ë¸ë¡œ í•œêµ­ì–´ Linux ëª…ë ¹ì–´ 100% ì •í™•ë„
- Griffin-style Hybrid (RNN+Attention 2:1)

#### 2.2.8 ë²”ìš© Agent (ëŒ€ì•ˆ)

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | íŠ¹ì§• |
|------|----------|------|
| **Youtu-LLM-2B** | 1.96B | 128K ì»¨í…ìŠ¤íŠ¸, Native Agentic, MLA |

**íŠ¹ì§•:**
- Dense MLA(Multi-head Latent Attention) ì•„í‚¤í…ì²˜
- End-to-End Agent ì‘ì—… ì™„ìˆ˜ ëŠ¥ë ¥

---

## 3. ë©”ëª¨ë¦¬(VRAM) ê²¬ì 

### 3.1 ì–‘ìí™” ê¸°ì¤€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

ëª¨ë“  ìˆ˜ì¹˜ëŠ” **llama.cpp GGUF** ê¸°ì¤€ì…ë‹ˆë‹¤.

| ëª¨ë¸ | FP16 | Q8_0 | Q4_K_M |
|------|------|------|--------|
| LFM2.5-1.2B (Brain) | ~2.4GB | ~1.5GB | ~0.8GB |
| Falcon-H1-Tiny-Tool-Calling (90M) | ~180MB | ~100MB | ~60MB |
| Falcon-H1-Tiny-Coder (90M) | ~180MB | ~100MB | ~60MB |
| Falcon-H1-Tiny-R-0.6B | ~1.2GB | ~700MB | ~400MB |
| Falcon-H1-Tiny-Multilingual (100M) | ~200MB | ~110MB | ~65MB |
| HybriKo-117M | ~240MB | ~130MB | ~75MB |
| LightOnOCR-2-1B | ~2GB | ~1.2GB | ~0.7GB |

### 3.2 êµ¬ì„±ë³„ ì´ ë©”ëª¨ë¦¬ ìš”êµ¬ëŸ‰

> **ğŸ–¥ï¸ PoC íƒ€ê²Ÿ í™˜ê²½:** Windows CPU-Only, 16GB RAM, Intel Core i5

#### PoC ê¶Œì¥ êµ¬ì„± (CPU-Only, 16GB RAM)
```
Brain:     LFM2.5-1.2B (Q4_K_M)        ~0.8GB
Reasoner:  Falcon-R-0.6B (Q4_K_M)      ~0.4GB  â† ì½”ë”©+ìˆ˜í•™ í†µí•©!
Tool:      Falcon-Tool-Calling (Q8_0)  ~0.1GB  (ì„ íƒì )
KV Cache + OS ì—¬ìœ                       ~0.7GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ê³„                                    ~2.0GB
```

**ì„¤ê³„ ê·¼ê±°:**
- **Falcon-R-0.6B = Coder + Reasoner í†µí•©:** LiveCodeBench 39% + MATH500 94%
- **LFM2.5ê°€ í•œêµ­ì–´ ì§ì ‘ ì²˜ë¦¬:** 8ê°œ ì–¸ì–´ ì§€ì›ìœ¼ë¡œ Multilingual Specialist ë¶ˆí•„ìš”
- **Falcon-Coder(90M) ì œì™¸:** Reasonerê°€ ì½”ë”©ë„ ì˜í•¨

> **âš ï¸ Thinking vs Instruct ì„ íƒ:**
> - `LFM2.5-1.2B-Thinking`: ë” ê¸´ ì¶”ë¡ , ì •í™•ë„ ë†’ì„ ìˆ˜ ìˆìŒ
> - `LFM2.5-1.2B-Instruct`: ì§§ì€ ì‘ë‹µ, ë¹ ë¦„
> - **â†’ PoCì—ì„œ ì‹¤í—˜ í›„ ê²°ì • ì˜ˆì •** (CPU í™˜ê²½ì—ì„œ ì†ë„ vs í’ˆì§ˆ íŠ¸ë ˆì´ë“œì˜¤í”„ í™•ì¸ í•„ìš”)

**ì í•© í™˜ê²½:** Windows 16GB RAM (CPU-Only), ë§¥ë¶ 16GB í†µí•© ë©”ëª¨ë¦¬

---

#### í™•ì¥ êµ¬ì„± (GPU ë³´ìœ  ì‹œ)
```
PoC ê¶Œì¥ êµ¬ì„±                            ~2.0GB
+ LightOnOCR-2-1B (Q4_K_M)              ~0.7GB  (ë¬¸ì„œ ì²˜ë¦¬)
+ LFM2.5-Audio-1.5B (ì„ íƒì )             ~1.0GB  (ìŒì„±)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ê³„                                     ~3.7GB
```

**ì í•© í™˜ê²½:** 8GB+ VRAM GPU, ë˜ëŠ” 32GB RAM ì‹œìŠ¤í…œ

### 3.3 ë™ì  ë¡œë”© ì „ëµ

| ëª¨ë¸ ìœ í˜• | ë¡œë”© ì „ëµ | ì´ìœ  |
|-----------|-----------|------|
| Brain (LFM2.5-1.2B) | **ìƒì‹œ ë¡œë”©** | ëª¨ë“  ìš”ì²­ì˜ ì§„ì…ì  |
| Reasoner (0.6B) | **ìƒì‹œ ë¡œë”©** | ì½”ë”©+ìˆ˜í•™ ë¹ˆë²ˆ, Q4ë©´ 0.4GBë¡œ ê°€ë²¼ì›€ |
| Tool-Calling (90M) | **í•„ìš”ì‹œ ë¡œë”©** | API í˜¸ì¶œ ì‹œì—ë§Œ í•„ìš” |
| OCR (1B) | **Just-In-Time** | ë¬¸ì„œ ì²˜ë¦¬ ì‹œì—ë§Œ í•„ìš”, ë¬´ê±°ì›€ |
| Audio (1.5B) | **Just-In-Time** | ìŒì„± ì…ì¶œë ¥ ì‹œì—ë§Œ í•„ìš” |

---

## 4. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 4.1 ì „ì²´ íë¦„ë„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ì‚¬ìš©ì ì…ë ¥                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ğŸ§  Brain (LFM2.5-1.2B-Thinking)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ 1. ì˜ë„ ë¶„ì„ (Intent Recognition)                        â”‚    â”‚
â”‚  â”‚ 2. ì‘ì—… ë¶„í•´ (Task Decomposition)                        â”‚    â”‚
â”‚  â”‚ 3. ì „ë¬¸ê°€ ì„ íƒ (Router)                                  â”‚    â”‚
â”‚  â”‚ 4. ê²°ê³¼ í†µí•© (Aggregator)                                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ”§ Specialist Pool                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ğŸ”¨ Tool   â”‚ â”‚ğŸ’» Coder  â”‚ â”‚ğŸ¤” Reason â”‚ â”‚ğŸŒ Multi  â”‚           â”‚
â”‚  â”‚  (90M)   â”‚ â”‚  (90M)   â”‚ â”‚ (600M)   â”‚ â”‚ (100M)   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚ğŸ“„ OCR    â”‚ â”‚ğŸ™ï¸ Audio  â”‚ â”‚ğŸ‡°ğŸ‡· Ko    â”‚                        â”‚
â”‚  â”‚  (1B)    â”‚ â”‚ (1.5B)   â”‚ â”‚ (117M)   â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ğŸ§  Brain (ê²°ê³¼ í†µí•©)                         â”‚
â”‚  - ê° Specialist ì¶œë ¥ ì¢…í•©                                       â”‚
â”‚  - ì¼ê´€ì„± ê²€ì¦                                                   â”‚
â”‚  - ìµœì¢… ì‘ë‹µ ìƒì„±                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ìµœì¢… ì‘ë‹µ                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 ë¼ìš°íŒ… ë¡œì§

Brain ëª¨ë¸ì´ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì „ë¬¸ê°€ë¥¼ ì„ íƒí•©ë‹ˆë‹¤:

```json
{
  "thinking": "ì‚¬ìš©ìê°€ í”¼ë³´ë‚˜ì¹˜ í•¨ìˆ˜ë¥¼ ìš”ì²­í–ˆìœ¼ë¯€ë¡œ ì½”ë”© ì „ë¬¸ê°€ì—ê²Œ ì „ë‹¬",
  "agents": [
    {
      "name": "CODER",
      "prompt": "Write a Python function to calculate the nth Fibonacci number",
      "priority": 1
    }
  ],
  "direct_answer": false
}
```

**ë¼ìš°íŒ… ê·œì¹™:**

| í‚¤ì›Œë“œ/íŒ¨í„´ | ì„ íƒë˜ëŠ” Agent |
|-------------|----------------|
| í•¨ìˆ˜, ì½”ë“œ, êµ¬í˜„, def, class | CODER |
| ê³„ì‚°, ì¦ëª…, ìˆ˜í•™, ë…¼ë¦¬, AIME | REASONER |
| ê²€ìƒ‰, API, í˜¸ì¶œ, function call | TOOL_CALLER |
| ë²ˆì—­, í•œêµ­ì–´, ì¼ë³¸ì–´ | MULTILINGUAL |
| PDF, ë¬¸ì„œ, OCR, ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ | OCR |
| ìŒì„±, ë§í•´ì¤˜, TTS | AUDIO |
| Linux, í„°ë¯¸ë„, bash | HYBRIKO |

### 4.3 Specialist í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

#### Tool-Calling Specialist
```xml
<tools>
[
  {"name": "search", "parameters": {"query": "string"}},
  {"name": "calculate", "parameters": {"expression": "string"}}
]
</tools>

User: {user_request}
Assistant:
```

#### Coder Specialist
```
You are a Python code generation assistant.
- Write clean, efficient code
- Include type hints
- Add docstrings

Task: {coding_task}

```python
```

---

## 5. ê¸°ìˆ  ìŠ¤íƒ

### 5.1 ì¶”ë¡  í”„ë ˆì„ì›Œí¬

| í”„ë ˆì„ì›Œí¬ | ì§€ì› í”Œë«í¼ | ì¥ì  |
|------------|-------------|------|
| **llama.cpp** | ëª¨ë“  í”Œë«í¼ | GGUF í‘œì¤€, ê°€ì¥ ë„“ì€ í˜¸í™˜ì„± |
| **MLX** | Apple Silicon | Metal ìµœì í™”, í†µí•© ë©”ëª¨ë¦¬ í™œìš© |
| **ONNX** | í¬ë¡œìŠ¤ í”Œë«í¼ | NPU ì§€ì› (AMD, Qualcomm) |
| vLLM | GPU ì„œë²„ | ê³ ì²˜ë¦¬ëŸ‰ ë°°ì¹˜ ì¶”ë¡  |

**PoC ê¶Œì¥:** `llama.cpp` (Python ë°”ì¸ë”© ì‚¬ìš©)

### 5.2 ì˜ì¡´ì„±

```toml
[project]
dependencies = [
    "llama-cpp-python>=0.3.0",
    "huggingface-hub>=0.25.0",
    "docling>=1.0.0",  # ë¬¸ì„œ íŒŒì‹±
    "rich>=13.0.0",     # CLI ì¶œë ¥
    "pydantic>=2.0.0",  # ë°ì´í„° ê²€ì¦
]
```

---

## 6. PoC êµ¬í˜„ ê³„íš

### 6.1 Phase 1: ê¸°ë³¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (Week 1)

**ëª©í‘œ:** Brain + 2ê°œ Specialist ì—°ë™

1. **í™˜ê²½ ì„¤ì •**
   - llama.cpp Python ë°”ì¸ë”© ì„¤ì¹˜
   - GGUF ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

2. **ModelPool í´ë˜ìŠ¤ êµ¬í˜„**
   ```python
   class ModelPool:
       def __init__(self, config: dict):
           self.brain = self._load_brain()
           self.specialists = self._load_specialists()
       
       def route_and_execute(self, user_input: str) -> str:
           plan = self.brain.plan(user_input)
           results = [self.specialists[a].execute(a.prompt) for a in plan.agents]
           return self.brain.aggregate(results)
   ```

3. **í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**
   - ë‹¨ìˆœ ì½”ë”©: "í”¼ë³´ë‚˜ì¹˜ í•¨ìˆ˜ ì‘ì„±í•´ì¤˜" â†’ CODER
   - ìˆ˜í•™: "123 + 456 = ?" â†’ Brain ì§ì ‘ ë˜ëŠ” REASONER

### 6.2 Phase 2: ì „ì²´ Specialist í†µí•© (Week 2)

1. **ì¶”ê°€ Specialist ì—°ë™**
   - Reasoning (0.6B)
   - Multilingual (100M)
   - HybriKo (117M)

2. **ë™ì  ë¡œë”© êµ¬í˜„**
   ```python
   class LazyModelLoader:
       def __getattr__(self, name):
           if name not in self._loaded:
               self._loaded[name] = self._load(name)
           return self._loaded[name]
   ```

3. **ë³µí•© ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸**
   - "AIME 2024 ë¬¸ì œ í’€ì–´ì¤˜" â†’ REASONER
   - "ì´ ì½”ë“œë¥¼ í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì¤˜" â†’ CODER â†’ MULTILINGUAL

### 6.3 Phase 3: ë¬¸ì„œ ì²˜ë¦¬ í™•ì¥ (Week 3)

1. **docling í†µí•©**
   - PDF â†’ Markdown ë³€í™˜
   - ì´ë¯¸ì§€ ì¶”ì¶œ

2. **LightOnOCR ë™ì  ë¡œë”©**
   - ìŠ¤ìº” ë¬¸ì„œì¼ ê²½ìš°ì—ë§Œ ë¡œë“œ
   - ìˆ˜ì‹ ì¸ì‹ í•„ìš”ì‹œ í™œìš©

### 6.4 Phase 4: ìµœì í™” ë° ë²¤ì¹˜ë§ˆí¬ (Week 4)

1. **ì„±ëŠ¥ ì¸¡ì •**
   - ì‘ë‹µ ì§€ì—° ì‹œê°„
   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
   - ì •í™•ë„ í‰ê°€

2. **ìµœì í™”**
   - ë°°ì¹˜ ì²˜ë¦¬
   - KV Cache ê³µìœ  ê²€í† 

---

## 7. ì˜ˆìƒ ì„±ëŠ¥

### 7.1 ì„±ëŠ¥ ë¹„êµ (ì˜ˆìƒ)

| ì‹œë‚˜ë¦¬ì˜¤ | ë‹¨ì¼ 4B ëª¨ë¸ | Tiny MoA (1.2B + ì „ë¬¸ê°€) |
|----------|-------------|-------------------------|
| ì½”ë”© ì‘ì—… | ì¤‘ìƒ | **ìƒ** (ì „ë¬¸ Coder) |
| ìˆ˜í•™ ì¶”ë¡  | ì¤‘ | **ìƒ** (ì „ë¬¸ Reasoner) |
| ë„êµ¬ í˜¸ì¶œ | ì¤‘ | **ìƒ** (ì „ë¬¸ Tool-Caller) |
| ì¼ë°˜ ëŒ€í™” | ìƒ | ì¤‘ìƒ (Brain ë‹¨ë…) |
| ë©”ëª¨ë¦¬ ì‚¬ìš© | 8GB+ | **2~4GB** |
| ë¡œë”© ì‹œê°„ | 10~20ì´ˆ | **3~5ì´ˆ** |

### 7.2 í•œê³„ì 

1. **ë³µì¡í•œ ë©€í‹°í™‰ ì¶”ë¡ :** Brainì˜ ë¶„í•´ ëŠ¥ë ¥ì— ì˜ì¡´
2. **ì§€ì‹ ì§‘ì•½ì  ì§ˆë¬¸:** 1.2B Brainì˜ ì§€ì‹ í•œê³„ (RAGë¡œ ë³´ì™„)
3. **Specialist ê°„ ì˜ì¡´ì„±:** ìˆœì°¨ í˜¸ì¶œ ì‹œ ì§€ì—° ëˆ„ì 

---

## 8. í™•ì¥ ê°€ëŠ¥ì„±

### 8.1 ì¶”ê°€ ê°€ëŠ¥í•œ Specialist

| ë¶„ì•¼ | í›„ë³´ ëª¨ë¸ | ë¹„ê³  |
|------|-----------|------|
| ì´ë¯¸ì§€ ì´í•´ | LFM2.5-VL-1.6B | Vision-Language |
| ë²•ë¥ /ì˜ë£Œ | ë„ë©”ì¸ SFT ëª¨ë¸ | ì¶”ê°€ íŒŒì¸íŠœë‹ í•„ìš” |
| ê²Œì„/ì—”í„°í…Œì¸ë¨¼íŠ¸ | FunctionGemma Fine-tune | ì•± ì œì–´ |

### 8.2 ìŠ¤ì¼€ì¼ ì—…

- **í´ë¼ìš°ë“œ ë°°í¬:** vLLM + GPU í´ëŸ¬ìŠ¤í„°
- **í•˜ì´ë¸Œë¦¬ë“œ:** ê²½ëŸ‰ ëª¨ë¸ ë¡œì»¬ + ë¬´ê±°ìš´ ëª¨ë¸ í´ë¼ìš°ë“œ
- **MCP ì„œë²„:** docling MCP ì„œë²„ë¡œ Agent ì—°ê²°

---

## 9. ì°¸ê³  ìë£Œ

### 9.1 ëª¨ë¸ ë§í¬

| ëª¨ë¸ | Hugging Face |
|------|--------------|
| LFM2.5-1.2B-Thinking | [LiquidAI/LFM2.5-1.2B-Thinking](https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking) |
| LFM2.5-1.2B-Instruct | [LiquidAI/LFM2.5-1.2B-Instruct](https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct) |
| Falcon-H1-Tiny-Tool-Calling | [tiiuae/Falcon-H1-Tiny-Tool-Calling-90M](https://huggingface.co/tiiuae/Falcon-H1-Tiny-Tool-Calling-90M) |
| Falcon-H1-Tiny-R-0.6B | [tiiuae/Falcon-H1-Tiny-R-0.6B](https://huggingface.co/tiiuae/Falcon-H1-Tiny-R-0.6B) |
| Falcon-H1-Tiny-Coder | [tiiuae/Falcon-H1-Tiny-Coder-90M](https://huggingface.co/collections/tiiuae/falcon-h1-tiny) |
| Falcon-H1-Tiny-Multilingual | [tiiuae/Falcon-H1-Tiny-Multilingual-100M-Instruct](https://huggingface.co/tiiuae/Falcon-H1-Tiny-Multilingual-100M-Instruct) |
| LightOnOCR-2-1B | [lightonai/LightOnOCR-2-1B](https://huggingface.co/lightonai/LightOnOCR-2-1B) |
| FunctionGemma | [google/functiongemma-270m-it](https://huggingface.co/google/functiongemma-270m-it) |
| Youtu-LLM-2B | [tencent/Youtu-LLM-2B](https://huggingface.co/tencent/Youtu-LLM-2B) |
| HybriKo-117M | [Yaongi/HybriKo-117M-LinuxFC-SFT-v2](https://huggingface.co/Yaongi/HybriKo-117M-LinuxFC-SFT-v2) |
| docling | [GitHub](https://github.com/docling-project/docling) |

### 9.2 ë¸”ë¡œê·¸ ë° ë…¼ë¬¸

- [Falcon-H1-Tiny ê¸°ìˆ  ë¸”ë¡œê·¸](https://huggingface.co/spaces/tiiuae/tiny-h1-blogpost)
- [LiquidAI LFM2.5 ë¸”ë¡œê·¸](https://www.liquid.ai/blog/introducing-lfm2-5-the-next-generation-of-on-device-ai)
- [Anti-curriculum í•™ìŠµ ì „ëµ](https://huggingface.co/spaces/tiiuae/tiny-h1-blogpost#falcon-h1-tiny-r-paving-the-way-for-a-new-pretraining-paradigm-for-reasoning-models)

---

## 10. ê²°ë¡ 

**Tiny MoA**ëŠ” "GPU Poor" í™˜ê²½ì—ì„œë„ ê³ í’ˆì§ˆ AI ê²½í—˜ì„ ì œê³µí•  ìˆ˜ ìˆëŠ” í˜„ì‹¤ì ì¸ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤.

**í•µì‹¬ ë©”ì‹œì§€:**
1. **4B ë‹¨ì¼ ëª¨ë¸ < 1.2B Brain + ì „ë¬¸ê°€ êµ°ë‹¨** (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
2. **90M~600M ëª¨ë¸ë„ íŠ¹í™” í•™ìŠµìœ¼ë¡œ SoTA ë‹¬ì„±** (Falcon-H1-Tiny ì¦ëª…)
3. **llama.cpp + GGUFë¡œ ì¦‰ì‹œ êµ¬í˜„ ê°€ëŠ¥** (ìƒíƒœê³„ ì„±ìˆ™)

ë‹¤ìŒ ë‹¨ê³„ë¡œ `src/poc/` ë””ë ‰í† ë¦¬ì—ì„œ PoC êµ¬í˜„ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
