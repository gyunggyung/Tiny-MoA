[ğŸ‡°ğŸ‡· í•œêµ­ì–´](README.md) | **ğŸ‡ºğŸ‡¸ English**

# ğŸ¤– Tiny MoA v2.1 (Unified Agentic System)

> **"AI Legion for the GPU Poor"** - A 1.2B Thinking Model self-plans and orchestrates a 600M Reasoner + 90M Tool Caller to solve complex tasks. âœ¨

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10+-green.svg)](https://python.org)
[![uv](https://img.shields.io/badge/uv-0.9+-purple.svg)](https://github.com/astral-sh/uv)
[![Status](https://img.shields.io/badge/Status-PoC-yellow.svg)]()

![Tiny MoA Demo](docs/img/tiny-moa-demo.gif)

---

## âœ¨ Key Features

- ğŸ§  **Multi-Agent & Thinking**: LFM2.5-1.2B-Thinking (Brain) creates plans, collaborating with Reasoner (600M) and Tool Caller (90M).
- ğŸ–¥ï¸ **Interactive TUI**: Rich-based real-time task board visualizing inter-agent collaboration.
- ğŸ”§ **Advanced Tooling**: Weather, Search (DuckDuckGo), File RAG, System Control, and more.
- ğŸŒ **English-First Strategy**: Reasons in English and translates to the user's language for speed and accuracy.
- âš¡ **GPU-Free**: Runs smoothly on 16GB RAM CPU environments.

---

## ğŸ“‹ Table of Contents

- [Quick Start](#-quick-start)
- [How to Run](#-how-to-run)
- [Model Composition](#-model-composition)
- [Architecture](#-architecture)
- [Project Structure](#-project-structure)
- [Roadmap](#-roadmap)

---

## ğŸš€ Quick Start

### 1. Clone Repository

```bash
git clone https://github.com/gyunggyung/Tiny-MoA.git
cd Tiny-MoA
```

### 2. Install uv (Recommended)

```powershell
# Windows PowerShell
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# Verify installation
uv --version
```

### 3. Install Dependencies

```bash
# Setup check with uv (Recommended - Fast!)
uv sync

# Or using pip
pip install -r requirements.txt
```

### 4. Download Models

```bash
# Brain (LFM2.5-1.2B-Thinking) - *New in v2.1*
huggingface-cli download LiquidAI/LFM2.5-1.2B-Thinking-GGUF \
    --include "*Q4_K_M.gguf" --local-dir ./models/brain

# Reasoner (Falcon-R-0.6B)
huggingface-cli download tiiuae/Falcon-H1-Tiny-R-0.6B-GGUF \
    --include "*Q4_K_M.gguf" --local-dir ./models/reasoner
```

---

## ğŸƒ How to Run

### Using uv (Recommended)

```bash
# 1. Basic Run (TUI Mode + Thinking)
uv run python -m tiny_moa.main --thinking --show-thinking --tui --query "Compare the weather in Seoul and Tokyo"

# 2. Interactive Mode
uv run python -m tiny_moa.main --interactive

# 3. Long Context Parsing (For complex reports)
uv run python -m tiny_moa.main --thinking --tui --n-ctx 12288 --query "..."

# 4. File Reference (RAG)
uv run python -m tiny_moa.main --tui --query "@[1706.03762v7-split.pdf] What is the main idea of this paper?"

# 5. Web Search (News/Info)
uv run python -m tiny_moa.main --tui --query "Find the latest AI news"

```

### Using pip

```bash
# PYTHONPATH setup required
$env:PYTHONPATH = "src"
python -m tiny_moa.main --query "How is the weather in Seoul?"
```

### Execution Example

```
ğŸ“ Input: How is the weather in Seoul?
ğŸŒ Translation: ko â†’ en
ğŸ§  Routing: TOOL
ğŸ”§ Executing get_weather
â•­â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ get_weather Result â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ temperature: -2Â°C                    â”‚
â”‚ condition: Light snow                â”‚
â”‚ humidity: 63%                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
ğŸŒ Translation: en â†’ ko
ğŸ’¬ Response: The weather in Seoul is -2Â°C with light snow.
```

---

## ğŸ§© Model Composition

| Role | Model | Parameters | Memory |
|------|------|----------|--------|
| ğŸ§  **Brain** | LFM2.5-1.2B-Thinking | 1.17B | ~0.8GB |
| ğŸ¤” **Reasoner** | Falcon-H1-Tiny-R-0.6B | 600M | ~0.4GB |
| ğŸ”§ **Tool Caller** | Falcon-Tool-Calling-90M | 90M | ~0.1GB |

> **Total Memory**: ~2GB (CPU-Only, runs smoothly on 16GB RAM)

---

## ğŸ—ï¸ Architecture

```
User Input (Multilingual)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ğŸŒ Translation Pipeline            â”‚
â”‚  - Language Detect (KR, JP, CN, etc.)   â”‚
â”‚  - Translate to English                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ğŸ§  Brain (LFM2.5-1.2B)             â”‚
â”‚  - Intent Analysis                      â”‚
â”‚  - Routing: TOOL / REASONER / DIRECT    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
    â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼                 â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TOOL   â”‚     â”‚ REASONER â”‚   â”‚  DIRECT  â”‚
â”‚ Weather/ â”‚     â”‚ Code/Math â”‚   â”‚ Chat     â”‚
â”‚ Search  â”‚     â”‚          â”‚   â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ğŸŒ Response Translation             â”‚
â”‚  - English â†’ Original Language          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
   Final Response (Original Language)
```

---

## ğŸ“‚ Project Structure

```
Tiny-MoA/
â”œâ”€â”€ pyproject.toml          # uv project configuration
â”œâ”€â”€ uv.lock
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ README_EN.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ docs/                   # Documentation & Plans
â”œâ”€â”€ models/                 # GGUF Models (Brain, Reasoner)
â”œâ”€â”€ rag_storage/            # RAG Vector DB (ChromaDB)
â””â”€â”€ src/
    â”œâ”€â”€ doc_processing/     # Document Conversion (Docling)
    â”‚   â””â”€â”€ converter.py
    â”œâ”€â”€ rag/                # RAG Engine
    â”‚   â”œâ”€â”€ engine.py       # RAG Logic
    â”‚   â””â”€â”€ store.py        # Vector Store
    â”œâ”€â”€ tiny_moa/           # Main Package
    â”‚   â”œâ”€â”€ cowork/         # Tiny Cowork (Agentic Workflow)
    â”‚   â”‚   â”œâ”€â”€ workers/    # Specialized Workers (Brain, Tool, etc.)
    â”‚   â”‚   â”œâ”€â”€ planner.py  # Task Planner
    â”‚   â”‚   â””â”€â”€ workspace.py# File System Access
    â”‚   â”œâ”€â”€ ui/             # TUI (Rich)
    â”‚   â”œâ”€â”€ brain.py        # Thinking Model Wrapper
    â”‚   â”œâ”€â”€ reasoner.py     # Falcon Wrapper
    â”‚   â”œâ”€â”€ orchestrator.py # Central Controller
    â”‚   â””â”€â”€ main.py         # Entry Point
    â”œâ”€â”€ tools/              # Tool Use
    â”‚   â”œâ”€â”€ executor.py     # Tool Executor (Search, Weather, etc.)
    â”‚   â””â”€â”€ schema.py       # Tool Definitions
    â””â”€â”€ translation/        # Translation Pipeline
```

---

## ğŸ“… Roadmap

- [x] **Phase 0:** Model Research & Architecture Design
- [x] **Phase 1:** Basic Brain + Reasoner Implementation
- [x] **Phase 2:** Tool Calling (Weather, Search, Calc, Time)
- [x] **Phase 3:** Translation Pipeline (English-First Strategy)
- [x] **Phase 4:** TUI & Thinking Model Integration (v2.1)
- [x] **Phase 5:** Docling Document Conversion
- [ ] **Phase 5:** [Agent Ecosystem](docs/agent_ecosystem_vision.md) Construction
- [ ] **Phase 6:** [All-in-One GUI App](docs/tiny_cowork_app_vision.md) Development
- [ ] **Phase 7:** [Master Roadmap](docs/v2_1_master_roadmap.md) Achievement

---

## ğŸ“š References

| Model | Link |
|------|------|
| LFM2.5-1.2B-Instruct | [HuggingFace](https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct) |
| LFM2.5-1.2B-Thinking | [HuggingFace](https://huggingface.co/LiquidAI/LFM2.5-1.2B-Thinking) |
| Falcon-H1-Tiny-R-0.6B | [HuggingFace](https://huggingface.co/tiiuae/Falcon-H1-Tiny-R-0.6B) |
| Falcon-Tool-Calling | [HuggingFace](https://huggingface.co/tiiuae/Falcon-H1-Tiny-Tool-Calling-90M) |

---

## ğŸ“„ License

This project is distributed under the **Apache 2.0** License.

---

## ğŸ“¬ Contact

- **Author:** [gyunggyung](https://github.com/gyunggyung)
- **Issues:** [GitHub Issues](https://github.com/gyunggyung/Tiny-MoA/issues)

---

<p align="center">
  <b>ğŸš€ Even the GPU Poor can enjoy AI! ğŸš€</b>
</p>
